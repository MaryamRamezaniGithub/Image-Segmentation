{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation-models-pytorch\n",
        "!pip install -U git+https://github.com/albumentations-team/albumentations"
      ],
      "metadata": {
        "id": "DF2vSng4OfMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/parth1620/Human-segmentation-Dataset-master.git"
      ],
      "metadata": {
        "id": "xDLaKN6YUImp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/contect/Human-Segmentation-Dataset-master')\n"
      ],
      "metadata": {
        "id": "u_fjjgmNdrSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import helper"
      ],
      "metadata": {
        "id": "tHEAXqEAdrVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_FILE=\"/content/Human-segmentation-Dataset-master/train.csv\"\n",
        "DATA_DIR=\"/content/\"\n",
        "DEVICE=\"cuda\"\n",
        "EPOCHS=25\n",
        "LR=0.003\n",
        "BATCH_SIZE=16\n",
        "IMG_SIZE=320\n",
        "ENCODER='timm-efficientnet-b0'\n",
        "WEIGHTS='imagenet'"
      ],
      "metadata": {
        "id": "zTI1KmeKdrYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(CSV_FILE)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "2SaBNExIdrbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row=df.iloc[1]\n",
        "image_path=row.images\n",
        "mask_path=row.masks"
      ],
      "metadata": {
        "id": "1Q1f9Lcpd7nR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image=cv2.imread(image_path)\n",
        "print(image)"
      ],
      "metadata": {
        "id": "erLTG9TNeBDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
      ],
      "metadata": {
        "id": "IdBhxK48fu5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask=cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)/255.0"
      ],
      "metadata": {
        "id": "srU9OPD3fSPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f, (ax1,ax2)=plt.subplots(1 , 2, figsize=(10,5))\n",
        "ax1.set_title(\"IMAGE\")\n",
        "ax1.imshow(image)\n",
        "ax2.set_title(\"MASK\")\n",
        "ax2.imshow(mask)"
      ],
      "metadata": {
        "id": "j9gmRQSyeBGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, valid_df= train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "EPxz_KsteBJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A"
      ],
      "metadata": {
        "id": "NFoLxZq3eBM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_augs():\n",
        "  return A.compose([\n",
        "      A.Resize(IMG_SIZE, IMG_SIZE),\n",
        "      A.HorizontalFlip(p=0.5),\n",
        "      A.VerticalFlip(p=0.5)\n",
        "  ])"
      ],
      "metadata": {
        "id": "1dnxiGQIbR2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_valid_augs():\n",
        "  return A.compose([\n",
        "      A.Resize(IMG_SIZE, IMG_SIZE)\n",
        "  ])"
      ],
      "metadata": {
        "id": "3GOrNyFgbR5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Custom Dataset"
      ],
      "metadata": {
        "id": "DUldNfrmczyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "lkWtNg__c9II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class  SegmentationDataset(Dataset):\n",
        "     def  __init__(self, df, augmentations):\n",
        "         self.df=df\n",
        "         self.augmentations=augmentations\n",
        "\n",
        "     def  __len__(self):\n",
        "         return len(self.df)\n",
        "\n",
        "     def  __getitem__(self, idx):\n",
        "         row=self.df.iloc[idx]\n",
        "         image_path=row.images\n",
        "         mask_path=row.masks\n",
        "         image=cv2.imread(image_path)\n",
        "         image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "         mask=cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "         mask=np.expand_dims(mask, axis=-1)\n",
        "     if  self.augmentations:\n",
        "         data=self.augmentations(image=image, mask=mask)\n",
        "         image=data[\"image\"]\n",
        "         mask=data[\"mask\"]\n",
        "     image=np.transpose(image, (2,0,1)).astype(np.float32)\n",
        "     mask=np.transpose(mask, (2,0,1)).astype(np.float32)\n",
        "     image=torch.Tensor(image)/255.0\n",
        "     mask=torch.round(torch.Tensor(mask)/255.0)\n",
        "     return image, mask"
      ],
      "metadata": {
        "id": "1lsoN9CF9NM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset=SegmentationDataset(train_df, get_train_agus())\n",
        "validset=SegmentationDataset(valid_df, get_valid_agus())"
      ],
      "metadata": {
        "id": "yKlBB2gY3T05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\" Size of Trainset: {len(trainset)}\")\n",
        "print(f\" Size of Validset: {len(validset)}\")"
      ],
      "metadata": {
        "id": "twCvp4SP3T-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx=3\n",
        "image , mask= trainset[idx]\n",
        "helper.show_image(image, mask)"
      ],
      "metadata": {
        "id": "XZurJcbU3UC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Dataset into Batches"
      ],
      "metadata": {
        "id": "e4iYZC5i-1-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "gLyeZlcz-59U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader=DataLoader(trainset, batch_size=BATCH_SIZE)\n",
        "validloader=DataLoader(validset, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "n5Qctqks_u4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total numbers of batches in trainloader: {len(trainloader)}\")\n",
        "print(f\"Total numbers of batches in validloader: {len(validloader)}\")"
      ],
      "metadata": {
        "id": "YOadbS32ADmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, mask in trainloader:\n",
        "  break"
      ],
      "metadata": {
        "id": "Xp50-pE8ADqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\" One batch image shape: {image.shape}\")\n",
        "print(f\" One batch mask shape: {mask.shape}\")"
      ],
      "metadata": {
        "id": "CWGnH6QzADtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Segmentation model"
      ],
      "metadata": {
        "id": "_QGfAffKHvDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "metadata": {
        "id": "WKOIYvdvADv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import segmentation_models_pytorch as smp"
      ],
      "metadata": {
        "id": "24GvIEO2H1cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from segmentation_models_pytorch.losses import DiceLoss"
      ],
      "metadata": {
        "id": "cc6bqDSLH5vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.conv import LazyConvTranspose2d\n",
        "from cv2.dnn import SegmentationModel\n",
        "class SegmentationModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SegmentationModel, self).__init__()\n",
        "    self.arc=smp.Unet(\n",
        "        encoder_name=ENCODER,\n",
        "        encoder_weights=WEIGHTS,\n",
        "        in_channels=3,\n",
        "        classes=1,\n",
        "        activation=None\n",
        "    )\n",
        "  def forward(self, images, masks=None):\n",
        "    logits=self.arc(images)\n",
        "    if mask != None:\n",
        "      loss1=DiceLoss(mode=\"binary\")(logits, masks)\n",
        "      loss2=nn.BCEWithLogitsLoss()(logits, masks)\n",
        "      return logits, loss1+loss2\n",
        "    return logits"
      ],
      "metadata": {
        "id": "Xhmewy2aJi-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=SegmentationModel()\n",
        "model.to(DEVICE);"
      ],
      "metadata": {
        "id": "y9kKBYXFN-la"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# create train and validation functions"
      ],
      "metadata": {
        "id": "2dEBPMNPfyX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fn(data_loader, model, optimizer):\n",
        "  model.train()\n",
        "  total_loss=0.0\n",
        "  for images, masks in tqdm(data_loader):\n",
        "    images=images.to(DEVICE)\n",
        "    masks=masks.to(DEVICE)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logits , loss=model(images, masks)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss+= loss.item()\n",
        "  return total_loss/len(data_loader)"
      ],
      "metadata": {
        "id": "ci6tH8y1OW1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_fn(data_loader, model):\n",
        "  model.eval()\n",
        "  total_loss=0.0\n",
        "  with torch.no_grad():\n",
        "    for images, masks in tqdm(data_loader):\n",
        "      images=images.to(DEVICE)\n",
        "      masks=masks.to(DEVICE)\n",
        "\n",
        "      logits , loss=model(images, masks)\n",
        "\n",
        "      total_loss += loss.item()\n",
        "  return total_loss/len(data_loader)"
      ],
      "metadata": {
        "id": "wccslPgaiMv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train The Model"
      ],
      "metadata": {
        "id": "Ww5Az4RmjYcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer=torch.optim.Adam(model.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "Loteg28njbMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss=np.Inf\n",
        "for i in range(EPOCHS):\n",
        "  train_loss=train_fn(trainloaader, model, optimizer)\n",
        "  valid_loss=eval_fn(validloader, model)\n",
        "  if valid_loss < best_valid_loss:\n",
        "    torch.save(model.state_dict(), \"best_model.pt\")\n",
        "    print(\"SAVE MODEL\")\n",
        "    best_valid_loss=valid_loss\n",
        "  print(f\" Epoch :{i+1} Train_loss :{train_loss} Valid_loss:{valid_loss}\")"
      ],
      "metadata": {
        "id": "DuyKNGVrjmwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# inference\n",
        "we are evaluating our model with validset"
      ],
      "metadata": {
        "id": "s5Xq7nHHpscp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx=20\n",
        "model.load_state_dict(torch.load(\"/content/best_model.pt\"))\n",
        "image, mask= validset[idx]\n",
        "logits_mask=model(image.to(DEVICE), unsqueeze(0))\n",
        "pred_mask=torch.sigmoid(logits_mask)\n",
        "pred_mask=(pred_mask> 0.5)* 1.0\n",
        "\n"
      ],
      "metadata": {
        "id": "yA1AV9mMpxK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "helper.show_image(image, mask, pred_mask.detach().cpu().squeeze(0))"
      ],
      "metadata": {
        "id": "OU9ZXfnCrBrG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}